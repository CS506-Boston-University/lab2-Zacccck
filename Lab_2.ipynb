{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXKV8OC7DcwV"
   },
   "source": [
    "For the beginning of this lab we are going to look at implementing different distance metrics.\n",
    "\n",
    "# You need to upload your completed notebook to the Github repo and also submit your Github repo link on Gradescope under Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ip0nE5CdDoNy"
   },
   "source": [
    "# Exercise 1) Write Python functions for the three metrics (Euclidean, Manhattan and Minkowski):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B92xBEzeyQPi"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.4' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUi1jJpFDbUj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean(a, b):\n",
    "    \"\"\"Euclidean (L2) distance\"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return float(np.sqrt(np.sum((a - b) ** 2)))\n",
    "\n",
    "def manhattan(a, b):\n",
    "    \"\"\"Manhattan (L1) distance\"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return float(np.sum(np.abs(a - b)))\n",
    "\n",
    "def minkowski(a, b, p=3):\n",
    "    \"\"\"Minkowski (Lp) distance, default p=3\"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    p = float(p)\n",
    "    return float(np.sum(np.abs(a - b) ** p) ** (1.0 / p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5R1L8XAD8KI"
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([4, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1YDOprREHuw"
   },
   "source": [
    "##For sample tests cases we expect\n",
    "* Euclidean = 5\n",
    "* Manhattan = 7\n",
    "* Minkokski (p = 3) ~ 4.4979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VWZeMmpH5Gt"
   },
   "outputs": [],
   "source": [
    "assert euclidean(a, b) == 5\n",
    "assert manhattan(a, b) == 7\n",
    "assert minkowski(a, b, p=3) == 4.497941445275415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0toQjdaEdiw"
   },
   "outputs": [],
   "source": [
    "a = np.array([2, 3, 5])\n",
    "b = np.array([2, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBsbiDShEYy8"
   },
   "source": [
    "For identical points we expect\n",
    "* Euclidean = 0.0\n",
    "* Manhattan = 0.0\n",
    "* Minkokski (p = 4) ~ 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZA6ayG7Icut"
   },
   "outputs": [],
   "source": [
    "assert euclidean(a, b) == 0.0\n",
    "assert manhattan(a, b) == 0.0\n",
    "assert minkowski(a, b, p=3) == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHn9exDsI6IF"
   },
   "source": [
    "#Exercise 2) In this part of the lab we will first be using the make_blobs method from sklearn.datasets, it creates for us an artificial dataset whereby we will inject outliers into our small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1457,
     "status": "ok",
     "timestamp": 1757540788728,
     "user": {
      "displayName": "Keanu Nichols",
      "userId": "15455753636681602329"
     },
     "user_tz": 240
    },
    "id": "ia2XRWvrcoFe",
    "outputId": "1799966f-cda9-4260-d645-0164cc630fc5"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# --- 1) Make clustered data ---\n",
    "X, y = make_blobs(n_samples=300,\n",
    "                  centers=[(-2, -2), (0, 4)],\n",
    "                  cluster_std=0.6,\n",
    "                  random_state=42)\n",
    "\n",
    "# --- 2) Inject outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# choose a wide box far outside clusters\n",
    "X_outliers = rng.uniform(low=-12, high=10, size=(n_outliers, 2))\n",
    "\n",
    "\n",
    "# combine\n",
    "#X_full = np.vstack([X, X_outliers])\n",
    "#y_full = np.hstack([y, [-1]*n_outliers])  # mark outliers as -1\n",
    "\n",
    "\n",
    "# --- 3) Plot ---\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"tab10\", s=40)\n",
    "plt.scatter(X_outliers[:,0], X_outliers[:,1],\n",
    "            c=\"red\", marker=\"*\", s=200, label=\"Outliers\")\n",
    "#plt.scatter(X_outliers[:, 0], X_outliers[:, 1], facecolors=\"none\", edgecolors=\"red\", s=120, linewidths=2, label=\"outliers\")\n",
    "plt.legend()\n",
    "plt.title(\"make_blobs clusters + clear outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oR_-B1kJJpt"
   },
   "source": [
    "#Our next tasks will be to use\n",
    "* First calculate Euclidean distances between points\n",
    "* In the next cell we will be calculating the cosine distance between points.\n",
    "\n",
    "###**Hint:** We can use the pairwise distance function from sklearn and call the appropriate distance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGDkJ5keWa_d"
   },
   "source": [
    "When looking at the plots, what kind of interpretations can you make, is euclidean or cosine better in this scenario? Which one seems to have a harder time with outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niUY0OEyVEwG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# --- 1) Make clustered data ---\n",
    "X, y = make_blobs(n_samples=300,\n",
    "                  centers=[(-2, -2), (0, 4)],\n",
    "                  cluster_std=0.6,\n",
    "                  random_state=42)\n",
    "\n",
    "# --- 2) Inject outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# choose a wide box far outside clusters\n",
    "X_outliers = rng.uniform(low=-12, high=10, size=(n_outliers, 2))\n",
    "\n",
    "\n",
    "# combine\n",
    "X_full = np.vstack([X, X_outliers])\n",
    "y_full = np.hstack([y, [-1]*n_outliers])  # mark outliers as -1\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise Euclidean distances ---\n",
    "D = pairwise_distances(X_full, metric='euclidean')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-2 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-2:][::-1]\n",
    "\n",
    "# --- 3) Plot ---\n",
    "plt.scatter(X_full[:, 0], X_full[:, 1], c=y_full, cmap=\"tab10\", s=40)\n",
    "plt.scatter(X_full[outlier_indices,0], X_full[outlier_indices,1],\n",
    "            facecolors=\"none\", edgecolors=\"red\",\n",
    "            s=120, linewidths=2, label=\"outliers\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"make_blobs clusters + clear outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zUFBxY-Vhrh"
   },
   "outputs": [],
   "source": [
    "# --- 1) Make clustered data ---\n",
    "X, y = make_blobs(n_samples=300,\n",
    "                  centers=[(-2, -2), (0, 4)],\n",
    "                  cluster_std=0.6,\n",
    "                  random_state=42)\n",
    "\n",
    "# --- 2) Inject outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# choose a wide box far outside clusters\n",
    "X_outliers = rng.uniform(low=-12, high=10, size=(n_outliers, 2))\n",
    "\n",
    "\n",
    "# combine\n",
    "X_full = np.vstack([X, X_outliers])\n",
    "y_full = np.hstack([y, [-1]*n_outliers])  # mark outliers as -1\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise Cosine distances ---\n",
    "D = pairwise_distances(X_full, metric='cosine')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-2 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-2:][::-1]\n",
    "\n",
    "# --- 3) Plot ---\n",
    "plt.scatter(X_full[:, 0], X_full[:, 1], c=y_full, cmap=\"tab10\", s=40)\n",
    "#plt.scatter(X_full[outlier_indices,0], X_full[outlier_indices,1],\n",
    "#            c=\"red\", marker=\"*\", s=200, label=\"Outliers\")\n",
    "\n",
    "plt.scatter(X_full[outlier_indices,0], X_full[outlier_indices,1],\n",
    "            facecolors=\"none\", edgecolors=\"red\",\n",
    "            s=120, linewidths=2, label=\"outliers\")\n",
    "plt.legend()\n",
    "plt.title(\"make_blobs clusters + clear outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V72SFv4gLWd5"
   },
   "source": [
    "#Exercise 3) In this part of the lab we will first be using the make_circle method from sklearn.datasets, it creates for us an artificial dataset whereby we will inject outliers into our small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1757540789031,
     "user": {
      "displayName": "Keanu Nichols",
      "userId": "15455753636681602329"
     },
     "user_tz": 240
    },
    "id": "h87nGN5Hf1i-",
    "outputId": "ca4649ca-5ca2-4412-c2e0-3edb45fc4390"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X, y = make_circles(n_samples=500, factor=0.8, noise=0.05, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2) Inject outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# choose a wide box far outside clusters\n",
    "X_outliers = rng.uniform(low=-8, high=8, size=(n_outliers, 2))\n",
    "\n",
    "# combine\n",
    "X_full = np.vstack([X, X_outliers])\n",
    "y_full = np.hstack([y, [-1]*n_outliers])  # mark outliers as -1\n",
    "\n",
    "plt.scatter(X_full[:,0], X_full[:,1], c='red', cmap=\"coolwarm\", s=20)\n",
    "\n",
    "plt.scatter(X_outliers[:,0], X_outliers[:,1],\n",
    "            c=\"blue\", marker=\"*\", s=200, label=\"Outliers\")\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"make_circles (true circular structure)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7V_vYjPOELJ"
   },
   "source": [
    "#Our next tasks will be to use\n",
    "* First calculate Euclidean distances between points\n",
    "* In the next cell we will be calculating the cosine distance between points.\n",
    "\n",
    "###**Hint:** We can use the pairwise distance function from sklearn and call the appropriate distance function.\n",
    "It's the same method we used previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yw_k_Op_YMmj"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "X, y = make_circles(n_samples=500, factor=0.8, noise=0.05, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2) Inject outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# choose a wide box far outside clusters\n",
    "X_outliers = rng.uniform(low=-8, high=8, size=(n_outliers, 2))\n",
    "\n",
    "# combine\n",
    "X_full = np.vstack([X, X_outliers])\n",
    "y_full = np.hstack([y, [-1]*n_outliers])  # mark outliers as -1\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise Euclidean distances ---\n",
    "D = pairwise_distances(X_full, metric='euclidean')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-2 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-2:][::-1]\n",
    "\n",
    "plt.scatter(X_full[:,0], X_full[:,1], c='blue', cmap=\"coolwarm\", s=20)\n",
    "\n",
    "#plt.scatter(X_full[outlier_indices,0], X_full[outlier_indices,1],\n",
    "#            c=\"blue\", marker=\"*\", s=200, label=\"Outliers\")\n",
    "\n",
    "plt.scatter(X_full[outlier_indices,0], X_full[outlier_indices,1],\n",
    "            facecolors=\"none\", edgecolors=\"red\",\n",
    "            s=120, linewidths=2, label=\"outliers\")\n",
    "\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"make_circles (true circular structure)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APPNboqUXQpd"
   },
   "outputs": [],
   "source": [
    "X, y = make_circles(n_samples=500, factor=0.8, noise=0.05, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2) Inject outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# choose a wide box far outside clusters\n",
    "X_outliers = rng.uniform(low=-8, high=8, size=(n_outliers, 2))\n",
    "\n",
    "# combine\n",
    "X_full = np.vstack([X, X_outliers])\n",
    "y_full = np.hstack([y, [-1]*n_outliers])  # mark outliers as -1\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise Cosine distances ---\n",
    "D = pairwise_distances(X_full, metric='cosine')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-2 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-2:][::-1]\n",
    "\n",
    "plt.scatter(X_full[:,0], X_full[:,1], c='blue', cmap=\"coolwarm\", s=20)\n",
    "\n",
    "plt.scatter(X_full[outlier_indices,0], X_full[outlier_indices,1],\n",
    "            facecolors=\"none\", edgecolors=\"red\",\n",
    "            s=120, linewidths=2, label=\"outliers\")\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"make_circles (true circular structure)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvHu8O3tON_3"
   },
   "source": [
    "#Exercise 4) In this part of the lab we will first be using numpy to create a set of points in a line, we will inject outliers into our small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1757540789327,
     "user": {
      "displayName": "Keanu Nichols",
      "userId": "15455753636681602329"
     },
     "user_tz": 240
    },
    "id": "q_yMsh_UfYT5",
    "outputId": "82aa662a-0a75-4b91-a812-83f3d07ceeef"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Points along a line y = 2x + 1 ---\n",
    "n_points = 100\n",
    "xs = np.linspace(-5, 5, n_points)\n",
    "ys = 2 * xs + 1\n",
    "line_points = np.column_stack((xs, ys))\n",
    "\n",
    "# --- 2. Add outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.default_rng(42)\n",
    "outliers = rng.uniform(low=[-15, -15], high=[25, 35], size=(n_outliers, 2))\n",
    "\n",
    "# --- 3. Combine ---\n",
    "X = np.vstack([line_points, outliers])\n",
    "labels = np.array([0]*len(line_points) + [-1]*len(outliers))  # mark outliers as -1\n",
    "\n",
    "# --- 4. Visualize ---\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(line_points[:,0], line_points[:,1], c=\"blue\", s=20)\n",
    "plt.scatter(outliers[:,0], outliers[:,1], facecolors=\"none\", edgecolors=\"red\",\n",
    "            s=120, linewidths=2)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Line with injected outliers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGTHHOJMOo38"
   },
   "source": [
    "#Our next tasks will be to use\n",
    "* First calculate Euclidean distances between points\n",
    "* In the next cell we will be calculating the cosine distance between points.\n",
    "\n",
    "###**Hint:** We can use the pairwise distance function from sklearn and call the appropriate distance function.\n",
    "It's the same method we used previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34Eodo5efLGg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Points along a line y = 2x + 1 ---\n",
    "n_points = 100\n",
    "xs = np.linspace(-5, 5, n_points)\n",
    "ys = 2 * xs + 1\n",
    "line_points = np.column_stack((xs, ys))\n",
    "\n",
    "# --- 2. Add outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.default_rng(42)\n",
    "outliers = rng.uniform(low=[-15, -15], high=[25, 35], size=(n_outliers, 2))\n",
    "\n",
    "# --- 3. Combine ---\n",
    "X = np.vstack([line_points, outliers])\n",
    "labels = np.array([0]*len(line_points) + [-1]*len(outliers))  # mark outliers as -1\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise Euclidean distances ---\n",
    "D = pairwise_distances(X, metric='euclidean')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-2 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-2:][::-1]\n",
    "\n",
    "# --- 4. Visualize ---\n",
    "plt.figure(figsize=(7,5))\n",
    "#plt.scatter(line_points[:,0], line_points[:,1], c=\"blue\", s=20)\n",
    "plt.scatter(X[:,0], X[:,1], c=\"blue\", s=20)\n",
    "plt.scatter(X[outlier_indices,0], X[outlier_indices,1], facecolors=\"none\", edgecolors=\"red\",\n",
    "            s=120, linewidths=2)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Line with injected outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdnt4Rx1et3H"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Points along a line y = 2x + 1 ---\n",
    "n_points = 100\n",
    "xs = np.linspace(-5, 5, n_points)\n",
    "ys = 2 * xs + 1\n",
    "line_points = np.column_stack((xs, ys))\n",
    "\n",
    "# --- 2. Add outliers ---\n",
    "n_outliers = 2\n",
    "rng = np.random.default_rng(42)\n",
    "outliers = rng.uniform(low=[-15, -15], high=[25, 35], size=(n_outliers, 2))\n",
    "\n",
    "# --- 3. Combine ---\n",
    "X = np.vstack([line_points, outliers])\n",
    "labels = np.array([0]*len(line_points) + [-1]*len(outliers))  # mark outliers as -1\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise Cosine distances ---\n",
    "D = pairwise_distances(X, metric='cosine')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-2 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-2:][::-1]\n",
    "\n",
    "# --- 4. Visualize ---\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X[:,0], X[:,1], c=\"blue\", s=20)\n",
    "plt.scatter(X[outlier_indices,0], X[outlier_indices,1], facecolors=\"none\", edgecolors=\"red\",\n",
    "            s=120, linewidths=2)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Line with injected outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_wORBKrO4O6"
   },
   "source": [
    "In the previous cells we have seen that cosine distance can struggle at times with low dimensional data, however with higher dimensional data like text/image embeddings it can perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBh_OKTVQoSV"
   },
   "source": [
    "#Exercise 5) In this first cell we will be calculating the cosine and euclidean distances for some simulated image data, we will see that cosine distance is more robust to variations in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1757540789700,
     "user": {
      "displayName": "Keanu Nichols",
      "userId": "15455753636681602329"
     },
     "user_tz": 240
    },
    "id": "eR418BSAlWWk",
    "outputId": "4f6a2b77-f6cb-4766-e90b-c68159aa68b0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# Simulate 512-d image embeddings\n",
    "# Image A: a \"reference image\"\n",
    "img_A = rng.normal(size=(1, 512))\n",
    "\n",
    "# Image B: same class (embedding points in nearly the same direction, scaled)\n",
    "img_B = img_A * 5.0 + rng.normal(scale=0.01, size=(1, 512))\n",
    "\n",
    "# Image C: different class (independent random vector)\n",
    "img_C = rng.normal(size=(1, 512))\n",
    "\n",
    "X = np.vstack([img_A, img_B, img_C])\n",
    "\n",
    "# Compute cosine vs Euclidean distances\n",
    "cos_dist = cosine_distances(X)\n",
    "euc_dist = euclidean_distances(X)\n",
    "\n",
    "print(\"Cosine distance matrix:\\n\", np.round(cos_dist, 3))\n",
    "print(\"\\nEuclidean distance matrix:\\n\", np.round(euc_dist, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9aBX0UZRhwE"
   },
   "source": [
    "# In this first cell we will be calculating the cosine and euclidean distances for some simulated text document data, we will see that cosine distance is more robust to variations in the data.\n",
    "\n",
    "TF-IDF simply refers to term frequency - inverse document frequency. It’s a statistical measure used in text mining and information retrieval to evaluate how important a word is to a document in a collection (corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRce2hABltX5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Imagine TF–IDF style vectors for documents\n",
    "doc_short = np.array([[1, 2, 3]])        # small vector\n",
    "doc_long  = np.array([[10, 20, 30]])     # same proportions, larger magnitude\n",
    "\n",
    "# Add a different document\n",
    "doc_diff  = np.array([[1, 0, 0]])        # very different direction\n",
    "\n",
    "X = np.vstack([doc_short, doc_long, doc_diff])\n",
    "\n",
    "# TO-DO\n",
    "# Compute distances\n",
    "cos_dist = cosine_distances(X)\n",
    "euc_dist = euclidean_distances(X)\n",
    "\n",
    "print(\"Cosine distance:\\n\", cos_dist)\n",
    "print(\"\\nEuclidean distance:\\n\", euc_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoA2jxKvSpPJ"
   },
   "source": [
    "#Exercise 6) Here we will be exploring a real world dataset from sklearn called the Breast-Cancer dataset from Wisconsin, it is a classic, real-world dataset that comes bundled for practice with classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1757540789701,
     "user": {
      "displayName": "Keanu Nichols",
      "userId": "15455753636681602329"
     },
     "user_tz": 240
    },
    "id": "33CxXE7Y6vm3",
    "outputId": "ca81f42e-0130-41d4-860b-bb4202d8bedb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# --- Load dataset ---\n",
    "cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu-ki3mUS_Lo"
   },
   "source": [
    "## Our task will simply be about exploring some of the features of the dataset, namely the area error and mean area, and looking at it their are any data outliers.\n",
    "\n",
    "### We will be again calculating the\n",
    "* Euclidean distance in the cell below\n",
    "* The next cell will be the cosine distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bgN3sHVPMMg"
   },
   "outputs": [],
   "source": [
    "# Use only two features: mean radius and mean area\n",
    "X2 = X[['area error', 'mean area']].values\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise Euclidean distances ---\n",
    "D = pairwise_distances(X2, metric='euclidean')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-5 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-5:][::-1]\n",
    "print(\"Top 5 outliers by mean distance:\", outlier_indices)\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X2[:,0], X2[:,1], c=\"lightblue\", s=40, edgecolor=\"k\", alpha=0.7)\n",
    "plt.scatter(X2[outlier_indices,0], X2[outlier_indices,1],\n",
    "            c=\"red\", marker=\"*\", s=200, label=\"Outliers\")\n",
    "plt.xlabel(\"Area error\")\n",
    "plt.ylabel(\"Mean Area\")\n",
    "plt.title(\"Breast Cancer Dataset: Outlier Detection via Euclidean Distance\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBSs3rVVPZiV"
   },
   "outputs": [],
   "source": [
    "# --- Compute pairwise Cosine distances ---\n",
    "D = pairwise_distances(X2, metric='cosine')\n",
    "\n",
    "# Distance profile: average distance to all other points\n",
    "mean_dist = D.mean(axis=1)\n",
    "\n",
    "# Identify potential outliers (top-5 by average distance)\n",
    "outlier_indices = np.argsort(mean_dist)[-5:][::-1]\n",
    "print(\"Top 5 outliers by mean distance:\", outlier_indices)\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X2[:,0], X2[:,1], c=\"lightblue\", s=40, edgecolor=\"k\", alpha=0.7)\n",
    "plt.scatter(X2[outlier_indices,0], X2[outlier_indices,1],\n",
    "            c=\"red\", marker=\"*\", s=200, label=\"Outliers\")\n",
    "plt.xlabel(\"Area error\")\n",
    "plt.ylabel(\"Mean Area\")\n",
    "plt.title(\"Breast Cancer Dataset: Outlier Detection via Cosine Distance\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVFj9fCN7Z6t"
   },
   "source": [
    "## Exercise 7) Here we simply look at a heatmap of different distance functions and seeing any patterns we observe with the data.    \n",
    "  \n",
    "  \n",
    "<br>\n",
    "\n",
    "### What are some of your observation about these heatmaps? Are some plots similar to others, additionally, does any of the heatmaps appear to struggle with detecting any similairty between the distances of a large amount of points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8gmUYrwQmbe"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Select just two features\n",
    "X2 = X[['area error', 'mean area']].values\n",
    "X2 = X2[:50,:]\n",
    "\n",
    "# TO-DO\n",
    "# --- Compute pairwise distances ---\n",
    "D_euclidean = pairwise_distances(X2, metric='euclidean')\n",
    "D_manhattan = pairwise_distances(X2, metric='manhattan')\n",
    "D_cosine    = pairwise_distances(X2, metric='cosine')\n",
    "\n",
    "print(\"Distance matrix shape:\", D_euclidean.shape)  # (569, 569)\n",
    "\n",
    "# --- Heatmap plotting function ---\n",
    "def plot_heatmap(D, title):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(D, cmap=\"viridis\", cbar_kws={'label': 'Distance'})\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Sample index\")\n",
    "    plt.ylabel(\"Sample index\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot heatmaps for each metric\n",
    "plot_heatmap(D_euclidean, \"Pairwise Euclidean Distance Heatmap\")\n",
    "plot_heatmap(D_manhattan, \"Pairwise Manhattan Distance Heatmap\")\n",
    "plot_heatmap(D_cosine,    \"Pairwise Cosine Distance Heatmap\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0_bBgSn7pWG"
   },
   "source": [
    "This cell we are exploring the different clusters in the dataset. We use the K-Mean clustering algorithm that we will be exploring in lectures soon. K-Means is one of the most popular unsupervised learning algorithms for clustering data into groups based on similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1757540791230,
     "user": {
      "displayName": "Keanu Nichols",
      "userId": "15455753636681602329"
     },
     "user_tz": 240
    },
    "id": "VD7JWfqu3tkq",
    "outputId": "99ae5d5d-1f96-462d-a90e-a50aaf2f8d6b"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "# Generate data\n",
    "\n",
    "X, y = make_blobs(n_samples=300, centers=2, cluster_std=0.60, random_state=0)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init='auto') # n_init='auto' for modern versions\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X')\n",
    "plt.title('K-means Clustering on make_blobs data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
